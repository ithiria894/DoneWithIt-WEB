{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "config.json: 100%|██████████| 1.05k/1.05k [00:00<?, ?B/s]\n",
      "c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\nicol\\.cache\\huggingface\\hub\\models--vilsonrodrigues--falcon-7b-instruct-sharded. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "model.safetensors.index.json: 100%|██████████| 16.9k/16.9k [00:00<?, ?B/s]\n",
      "model-00001-of-00015.safetensors: 100%|██████████| 1.68G/1.68G [03:46<00:00, 7.43MB/s]\n",
      "model-00002-of-00015.safetensors: 100%|██████████| 1.99G/1.99G [04:09<00:00, 7.97MB/s]\n",
      "model-00003-of-00015.safetensors: 100%|██████████| 1.82G/1.82G [03:49<00:00, 7.95MB/s]\n",
      "model-00004-of-00015.safetensors: 100%|██████████| 1.99G/1.99G [04:03<00:00, 8.17MB/s]\n",
      "model-00005-of-00015.safetensors: 100%|██████████| 1.99G/1.99G [04:04<00:00, 8.13MB/s]\n",
      "model-00006-of-00015.safetensors: 100%|██████████| 1.82G/1.82G [03:58<00:00, 7.63MB/s]\n",
      "model-00007-of-00015.safetensors: 100%|██████████| 1.99G/1.99G [04:16<00:00, 7.74MB/s]\n",
      "model-00008-of-00015.safetensors: 100%|██████████| 1.99G/1.99G [04:29<00:00, 7.37MB/s]\n",
      "model-00009-of-00015.safetensors: 100%|██████████| 1.82G/1.82G [03:57<00:00, 7.68MB/s]\n",
      "model-00010-of-00015.safetensors: 100%|██████████| 1.99G/1.99G [04:13<00:00, 7.83MB/s]\n",
      "model-00011-of-00015.safetensors: 100%|██████████| 1.99G/1.99G [04:22<00:00, 7.56MB/s]\n",
      "model-00012-of-00015.safetensors: 100%|██████████| 1.82G/1.82G [03:52<00:00, 7.83MB/s]\n",
      "model-00013-of-00015.safetensors: 100%|██████████| 1.99G/1.99G [04:25<00:00, 7.49MB/s]\n",
      "model-00014-of-00015.safetensors: 100%|██████████| 1.99G/1.99G [04:35<00:00, 7.22MB/s]\n",
      "model-00015-of-00015.safetensors: 100%|██████████| 828M/828M [01:50<00:00, 7.50MB/s]\n",
      "Downloading shards: 100%|██████████| 15/15 [1:00:29<00:00, 241.94s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 15/15 [02:24<00:00,  9.63s/it]\n",
      "generation_config.json: 100%|██████████| 117/117 [00:00<00:00, 33.2kB/s]\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the meaning for life?\n",
      "The meaning of life is subjective and varies from person to person. Some may find meaning in their relationships, careers, or personal growth, while others may find meaning in spiritual or philosophical pursuits. Ultimately, the meaning\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# Define the model name\n",
    "MODEL_NAME = \"vilsonrodrigues/falcon-7b-instruct-sharded\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Create a text generation pipeline\n",
    "text_generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Define a prompt\n",
    "prompt = \"What is the meaning for life?\"\n",
    "\n",
    "# Generate text based on the prompt\n",
    "generated_texts = text_generator(prompt, max_length=50, num_return_sequences=1)\n",
    "\n",
    "# Print the generated text\n",
    "for generated_text in generated_texts:\n",
    "    print(generated_text[\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the meaning for life?\n",
      "The meaning of life is subjective and varies from person to person. Some may find meaning in their relationships, careers, or personal growth, while others may find meaning in spiritual or philosophical pursuits. Ultimately, the meaning\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is the meaning for life?\"\n",
    "\n",
    "# Generate text based on the prompt\n",
    "generated_texts = text_generator(prompt, max_length=50, num_return_sequences=1)\n",
    "\n",
    "# Print the generated text\n",
    "for generated_text in generated_texts:\n",
    "    print(generated_text[\"generated_text\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
